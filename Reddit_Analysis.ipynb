{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base packages for analysis \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import WallStreetBets Reddit comment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments take hours to all load, it is about 2.5 million comments therefore the collected data has been prestored in a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sedawarp/anaconda3/envs/tensorflow/lib/python3.7/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/home/sedawarp/anaconda3/envs/tensorflow/lib/python3.7/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "# import reddit comment collection function \n",
    "from RedditScraper import *\n",
    "\n",
    "# Create dataframe of reddit comments of the last 60 days on wallstreetbets\n",
    "reddit_df = collect_subreddit_comments(after='60d', subreddit='wallstreetbets', columns=['body', 'score', 'created_utc'])\n",
    "\n",
    "# Save dataframe as csv\n",
    "reddit_df.to_csv('reddit_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sedawarp/anaconda3/envs/tensorflow/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3166: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "reddit_df = pd.read_csv('reddit_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocess dataframe shape (2600523, 5)\n",
      "Data after removing removed comments (1766638, 3)\n",
      "After preprocess dataframe shape (1766638, 6)\n"
     ]
    }
   ],
   "source": [
    "# import preprocessor class and preprocess comments and add datatime variables\n",
    "from TextPreprocessor import Preprocessor \n",
    "\n",
    "reddit_df = Preprocessor().preprocess_reddit(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2600497</th>\n",
       "      <td>stepmom stuck in a barrel fanfic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600498</th>\n",
       "      <td>double bs and now time for bb to gif emote fre...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600499</th>\n",
       "      <td>open up the casino</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600501</th>\n",
       "      <td>ah thats nice but the super speed is beyond ch...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600502</th>\n",
       "      <td>i am a bot from r wallstreetbets you submitted...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600505</th>\n",
       "      <td>that’s so fucking stupid and i’m so happy for you</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600506</th>\n",
       "      <td>no no i wanna see where this goes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600507</th>\n",
       "      <td>good on ya you fucking dirty ape</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600509</th>\n",
       "      <td>cheap vodka is your friend</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600510</th>\n",
       "      <td>this guy hates money</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600512</th>\n",
       "      <td>all my money is in amc 🦧🌙</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600513</th>\n",
       "      <td>😱</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600514</th>\n",
       "      <td>you’re going to make me hedge with some puts a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600516</th>\n",
       "      <td>ribeyes on the menu boys</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600517</th>\n",
       "      <td>really early in the morning and partially nake...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600518</th>\n",
       "      <td>your submission was removed from r wallstreetb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600519</th>\n",
       "      <td>cool acronym but isn’t true about uwm they’re ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600520</th>\n",
       "      <td>same thing happened before a crash</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600521</th>\n",
       "      <td>didnt check the sub since yesterday just want ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600522</th>\n",
       "      <td>ooooo boy we got a writer here</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.623987e+09</td>\n",
       "      <td>2021-06-18 03</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body  score  \\\n",
       "2600497                  stepmom stuck in a barrel fanfic     4.0   \n",
       "2600498  double bs and now time for bb to gif emote fre...    2.0   \n",
       "2600499                                 open up the casino    7.0   \n",
       "2600501  ah thats nice but the super speed is beyond ch...    7.0   \n",
       "2600502  i am a bot from r wallstreetbets you submitted...    0.0   \n",
       "2600505  that’s so fucking stupid and i’m so happy for you   10.0   \n",
       "2600506                 no no i wanna see where this goes     1.0   \n",
       "2600507                  good on ya you fucking dirty ape     2.0   \n",
       "2600509                         cheap vodka is your friend    2.0   \n",
       "2600510                              this guy hates money     2.0   \n",
       "2600512                          all my money is in amc 🦧🌙    4.0   \n",
       "2600513                                                  😱    3.0   \n",
       "2600514  you’re going to make me hedge with some puts a...    1.0   \n",
       "2600516                          ribeyes on the menu boys     1.0   \n",
       "2600517  really early in the morning and partially nake...    1.0   \n",
       "2600518  your submission was removed from r wallstreetb...    1.0   \n",
       "2600519  cool acronym but isn’t true about uwm they’re ...    1.0   \n",
       "2600520                 same thing happened before a crash   -1.0   \n",
       "2600521  didnt check the sub since yesterday just want ...    8.0   \n",
       "2600522                    ooooo boy we got a writer here     3.0   \n",
       "\n",
       "          created_utc           date month day  \n",
       "2600497  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600498  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600499  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600501  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600502  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600505  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600506  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600507  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600509  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600510  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600512  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600513  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600514  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600516  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600517  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600518  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600519  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600520  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600521  1.623987e+09  2021-06-18 03    06  18  \n",
       "2600522  1.623987e+09  2021-06-18 03    06  18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticker Analyisis - What is currently popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all comments mentioning selected stocks and counting freqquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mentions of ticker wish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sedawarp/Documents/WSB-Reddit-Sentiment-Indicator/StockParser.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tick['Stock'] = stock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find mentions of ticker spy\n",
      "find mentions of ticker clov\n",
      "find mentions of ticker hood\n",
      "find mentions of ticker bb\n",
      "find mentions of ticker srne\n",
      "find mentions of ticker whks\n",
      "find mentions of ticker sofi\n",
      "find mentions of ticker tsla\n",
      "find mentions of ticker clne\n",
      "find mentions of ticker spce\n",
      "find mentions of ticker clf\n",
      "find mentions of ticker gme\n",
      "find mentions of ticker amc\n",
      "find mentions of ticker body\n",
      "find mentions of ticker pltr\n",
      "find mentions of ticker baba\n",
      "find mentions of ticker tlry\n",
      "300371 individual comments of select stocks\n"
     ]
    }
   ],
   "source": [
    "from StockParser import WSBStockParser\n",
    "\n",
    "stockScanner = WSBStockParser()\n",
    "\n",
    "reddit_df_filtered = stockScanner.find_mentions(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spy     52967\n",
       "wish    34686\n",
       "clov    25945\n",
       "hood    22923\n",
       "bb      22585\n",
       "gme     21915\n",
       "amc     20805\n",
       "tsla    14940\n",
       "body    12967\n",
       "sofi    12409\n",
       "spce    10828\n",
       "clne    10279\n",
       "pltr     9783\n",
       "whks     8865\n",
       "baba     6555\n",
       "tlry     5999\n",
       "clf      5341\n",
       "srne      579\n",
       "Name: Stock, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df_filtered['Stock'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/sedawarp/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import self made vader class\n",
    "from SentimentGenerator import Vader\n",
    "\n",
    "# initalize vader object for sentiment generation\n",
    "v_sentiment = Vader()\n",
    "\n",
    "# assign new vader sentiment column and weighted sentiment \n",
    "reddit_df_filtered = v_sentiment.classify_list(reddit_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Stock</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>weighted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>okay which one of you autists loaded up on wis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ahh the old ecvt wish clne clov and bb baghold...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>wish finally dead</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>-0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>wish dip bought</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>unsure i wish i knew</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629146e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.1779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  score   created_utc  \\\n",
       "30   okay which one of you autists loaded up on wis...    1.0  1.629147e+09   \n",
       "59   ahh the old ecvt wish clne clov and bb baghold...    1.0  1.629147e+09   \n",
       "74                                  wish finally dead     1.0  1.629147e+09   \n",
       "78                                     wish dip bought    1.0  1.629147e+09   \n",
       "238                               unsure i wish i knew    1.0  1.629146e+09   \n",
       "\n",
       "              date month day Stock  vader_sentiment  weighted_sentiment  \n",
       "30   2021-08-16 20    08  16  wish           0.5574              0.5574  \n",
       "59   2021-08-16 20    08  16  wish           0.3612              0.3612  \n",
       "74   2021-08-16 20    08  16  wish          -0.3818             -0.3818  \n",
       "78   2021-08-16 20    08  16  wish           0.4019              0.4019  \n",
       "238  2021-08-16 20    08  16  wish           0.1779              0.1779  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported self created Roberta class for sentiment generation\n",
    "from SentimentGenerator import OpinionatedRoberta \n",
    "\n",
    "# Create sentiment generator object \n",
    "b_sentiment = OpinionatedRoberta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣤⣤⣤⣤⣤⣶⣦⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⡿⠛⠉⠙⠛⠛⠛⠛⠻⢿⣿⣷⣤⡀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⠋⠀⠀⠀⠀⠀⠀⠀⢀⣀⣀⠈⢻⣿⣿⡄⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⣸⣿⡏⠀⠀⠀⣠⣶⣾⣿⣿⣿⠿⠿⠿⢿⣿⣿⣿⣄⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⣿⣿⠁⠀⠀⢰⣿⣿⣯⠁⠀⠀⠀⠀⠀⠀⠀⠈⠙⢿⣷⡄⠀ ⠀⠀⣀⣤⣴⣶⣶⣿⡟⠀⠀⠀⢸⣿⣿⣿⣆🚀⠀⠀⠀⠀🚀⠀⠀⣿⣷⠀ ⠀⢰⣿⡟⠋⠉⣹⣿⡇⠀⠀⠀⠘⣿⣿⣿⣿⣷⣦⣤⣤⣤⣶⣶⣶⣶⣿⣿⣿⠀ ⠀⢸⣿⡇⠀⠀⣿⣿⡇⠀⠀⠀⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠃⠀ ⠀⣸⣿⡇⠀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠉⠻⠿⣿⣿⣿⣿⡿⠿⠿⠛⢻⣿⡇⠀⠀ ⠀⣿⣿⠁⠀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣧⠀⠀ ⠀⣿⣿⠀⠀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⠀⠀ ⠀⣿⣿⠀⠀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⠀⠀ ⠀⢿⣿⡆⠀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⡇⠀⠀ ⠀⠸⣿⣧⡀⠀⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⠃⠀⠀ ⠀⠀⠛⢿⣿⣿⣿⣿⣇⠀⠀⠀⠀⠀⣰⣿⣿⣷⣶⣶⣶⣶⠶⠀⢠⣿⣿⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⣿⣿⠀⠀⠀⠀⠀⣿⣿⡇⠀⣽⣿⡏⠁⠀⠀⢸⣿⡇⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⣿⣿⠀⠀⠀⠀⠀⣿⣿⡇⠀⢹⣿⡆⠀⠀⠀⣸⣿⠇⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⢿⣿⣦⣄⣀⣠⣴⣿⣿⠁⠀⠈⠻⣿⣿⣿⣿⡿⠏⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠈⠛⠻⠿⠿⠿⠿⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ wish\n",
      " wish ⠀⠀⠀⠘⣀⠄⠊⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀ ⣿⣿⣿⣿⣿⣿⣿⣿⡿⠿⠛⠛⠛⠋⠉⠈⠉⠉⠉⠉⠛⠻⢿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⡿⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠛⢿⣿⣿⣿⣿ ⣿⣿⣿⣿⡏⣀⠀⠀⠀⠀⠀⠀⠀⣀⣤⣤⣤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠙⢿⣿⣿ ⣿⣿⣿⢏⣴⣿⣷⠀⠀⠀⠀⠀⢾⣿⣿⣿⣿⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀⠈⣿⣿ ⣿⣿⣟⣾⣿⡟⠁⠀⠀⠀⠀⠀⢀⣾⣿⣿⣿⣿⣿⣷⢢⠀⠀⠀⠀⠀⠀⠀⢸⣿ ⣿⣿⣿⣿⣟⠀⡴⠄⠀⠀⠀⠀⠀⠀⠙⠻⣿⣿⣿⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⣿ ⣿⣿⣿⠟⠻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠶⢴⣿⣿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⣿ ⣿⣁⡀⠀⠀⢰⢠⣦⠀⠀⠀⠀⠀⠀⠀⠀⢀⣼⣿⣿⣿⣿⣿⡄⠀⣴⣶⣿⡄⣿ ⣿⡋⠀⠀⠀⠎⢸⣿⡆⠀⠀⠀⠀⠀⠀⣴⣿⣿⣿⣿⣿⣿⣿⠗⢘⣿⣟⠛⠿⣼ ⣿⣿⠋⢀⡌⢰⣿⡿⢿⡀⠀⠀⠀⠀⠀⠙⠿⣿⣿⣿⣿⣿⡇⠀⢸⣿⣿⣧⢀⣼ ⣿⣿⣷⢻⠄⠘⠛⠋⠛⠃⠀⠀⠀⠀⠀⢿⣧⠈⠉⠙⠛⠋⠀⠀⠀⣿⣿⣿⣿⣿ ⣿⣿⣧⠀⠈⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠟⠀⠀⠀⠀⢀⢃⠀⠀⢸⣿⣿⣿⣿ ⣿⣿⡿⠀⠴⢗⣠⣤⣴⡶⠶⠖⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⡸⠀⣿⣿⣿⣿ ⣿⣿⣿⡀⢠⣾⣿⠏⠀⠠⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⠉⠀⣿⣿⣿⣿ ⣿⣿⣿⣧⠈⢹⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⣿⣿⣿⣿ ⣿⣿⣿⣿⡄⠈⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣴⣾⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣦⣄⣀⣀⣀⣀⠀⠀⠀⠀⠘⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⡄⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣧⠀⠀⠀⠙⣿⣿⡟⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠇⠀⠁⠀⠀⠹⣿⠃⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡿⠛⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⢐⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⠿⠛⠉⠉⠁⠀⢻⣿⡇⠀⠀⠀⠀⠀⠀⢀⠈⣿⣿⡿⠉⠛⠛⠛⠉⠉ ⣿⡿⠋⠁⠀⠀⢀⣀⣠⡴⣸⣿⣇⡄⠀⠀⠀⠀⢀⡿⠄⠙⠛⠀⣀⣠⣤⣤⠄\n",
      "just buy a index fund https finance yahoo com quote spy chart p spy eyjpbnrlcnzhbciindlzwsilcjwzxjpbrpylesimswidgltzvvuaxqiombgwsimnhbmrszvdpzhroijoljmodyotawmzgzmtqxnzusimzsaxbwzwqiomzhbhnllcjbxbwvvbmrlcmxhesidhjzswiywrqijpcnvllcjjcmzchhaxiionrydwusimnoyxjvhlwzsiimxpbmuilcjlehrlbmrlzcizmfscusimhcmtldfnlcnpbzijpfswiywdncmvnyxrpbuexblijoibhsyyisimnoyxjunhbguioijwzxjjzwiiwicrzgllcyieyligixbwgdwkcukajcieyjexblijoidmsihvuzhiilcjpbnbdhmionsiawqioiligixbwgdwkcukajcisimrpcbsyxkioiligixbwgdwkcukajcjlcjvdxrwdxrzijpilvwifzvbhvtzsiiimwmgiwnjeilcjebduifzvbhvtzsiiinmzjmzmeifswicgfuzwwioijjagfydcisinbhcmftzxrlcnmionsidlkdghgywnbiiojaundusimnoyxjtmftzsiimnoyxjinfswicgfuzwxzijpimnoyxjijpinblcmnlbnqiojesimrpcbsyxkioijtufkilcjjagfydehbwuioijjagfydcisimluzgvijowlcjqxhpcyieyjuywlijoiyhhcnqilcjwbnpdglvbiibnvsbhsinlheglztehtijpbxswiewfaxnssfmiolsiyhhcnqilcligixbwgdwkcukajcjdfxsinnldfnwywionsibxvsdglwbgllciinswiymfzzsiinllyxiilcjwzxjpbrpylesieyjwzxjpbqiojesimludgvydmfsijoidvlayjfswibgluzvdpzhroijoylcjzdhjpcgvkqmfjadybvuzcidhjzswizxzlbnrzijpcnvllcjjbxvciiiimwmdgxzjiilcjzdhjpcgvkqmfjadybvkijpcnvllcjldmvudehccieyjjbjwbjhdguionsizglcyidhjzswicbsaxrzijpcnvlfswiclnrgvijpfxsinnbwjvbhmioltinnbwjvbciilnqwsisinnbwjvbeiamvjdcieyjzewibwioijtufkilcjxdwzvrcguioijfveyilcjlegnoywnzvrpbwvablijoiqwlcmljysozxdfwwyayjlcjwzxjpbrpylesimswiawzxjywwioijzwvriiwidgltzvvuaxqiombgwsinnldfnwywionsibxvsdglwbgllciinswiymfzzsiinllyxiilcjwzxjpbrpylesieyjwzxjpbqiojesimludgvydmfsijoidvlayjfxseyjzewibwioijhqzgiiwicltymstjqzwnijpinnbwjvbciikddpuyifswicgvyawkawnpdhkiojesimludgvydmfsijoidvlayisinrpbwvvbmlijpudwxslcjzzxrtcgfuijpimbhrpcgxpzxiiojusimjhcuioijzwfyiiwicgvyawkawnpdhkionsicgvyawkijoxlcjpbnrlcnzhbciindlzwsifxsimlkijoirmriisinbhcmftzxrlcnmionsiysbiioiijzmzlnzgiiwidlkdggiojisimlzqtcgfyaxnvbiidhjzswichhcmvzqxhpcyidhjzswiyhhcnroywlijoiyhhcnqilcjzewibxpymplyqionsicltymsijoirmrijlcjwywlbciimnoyxjiiwizmlsbedhchmiomzhbhnllcjhyrpbioijhzgqtcvyawvziiwicltymsijoirmriisimdhcerpcbsyxltdhlszsiinryywzcgfyzwiiwibmftzsiikddpuyilcjvdmvyqhhcnqionrydwusinvzzunoyxjtgvnzwkijpcnvllcjozwlnahrqzxjjzwywdlijowljcsimwywnpdhkiojesimhpzhsawdodgfibguionrydwusinrcguioijsawliiwicrbguioijzdhhfbgluzvjagfydcjfvsimncrvbvjhbmdlijpudwxsfq \n",
      "🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀 🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀 🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀 🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀 🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀 🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀 🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀 🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀 🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀🍀 clov\n",
      "this is hood right now are you going in ⢀⡴⠑⡄⠀⠀⠀⠀⠀⠀⠀⣀⣀⣤⣤⣤⣀⡀⠀⠀⠀⠀ ⠸⡇⠀⠿⡀⠀⠀⠀⣀⡴⢿⣿⣿⣿⣿⣿⣿⣿⣷⣦⡀⠀⠀⠀ ⠀⠀⠀⠀⠑⢄⣠⠾⠁⣀⣄⡈⠙⣿⣿⣿⣿⣿⣿⣿⣿⣆⠀⠀ ⠀⠀⠀⠀⢀⡀⠁⠀⠀⠈⠙⠛⠂⠈⣿⣿⣿⣿⣿⠿⡿⢿⣆⠀ ⠀⠀⠀⢀⡾⣁⣀⠀⠴⠂⠙⣗⡀⠀⢻⣿⣿⠭⢤⣴⣦⣤⣹⠀ ⠀⠀⢀⣾⣿⣿⣿⣷⣮⣽⣾⣿⣥⣴⣿⣿⡿⢂⠔⢚⡿⢿⣿⣦ ⠀⢀⡞⠁⠙⠻⠿⠟⠉⠀⠛⢹⣿⣿⣿⣿⣿⣌⢤⣼⣿⣾⣿⡟ ⠀⣾⣷⣶⠇⠀⠀⣤⣄⣀⡀⠈⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇ ⠀⠉⠈⠉⠀⠀⢦⡈⢻⣿⣿⣿⣶⣶⣶⣶⣤⣽⡹⣿⣿⣿⣿⡇ ⠀⠀⠀⠀⠀⠀⠀⠉⠲⣽⡻⢿⣿⣿⣿⣿⣿⣿⣷⣜⣿⣿⣿⡇ ⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣷⣶⣮⣭⣽⣿⣿⣿⣿⣿⣿⣿⠀ ⠀⠀⠀⠀⠀⠀⣀⣀⣈⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠇⠀ ⠀⠀⠀⠀⠀⠀⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠀⠀⠀⠀⠀ ⠄⠄⠄⠄⠄⠄⣠⢼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⡄⠄⠄⠄ ⠄⠄⣀⣤⣴⣾⣿⣷⣭⣭⣭⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⡀⠄⠄ ⠄⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣸⣿⣿⣧⠄⠄ ⠄⣿⣿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣯⢻⣿⣿⡄⠄ ⠄⢸⣿⣮⣿⣿⣿⣿⣿⣿⣿⡟⢹⣿⣿⣿⡟⢛⢻⣷⢻⣿⣧⠄ ⠄⠄⣿⡏⣿⡟⡛⢻⣿⣿⣿⣿⠸⣿⣿⣿⣷⣬⣼⣿⢸⣿⣿⠄ ⠄⠄⣿⣧⢿⣧⣥⣾⣿⣿⣿⡟⣴⣝⠿⣿⣿⣿⠿⣫⣾⣿⣿⡆ ⠄⠄⢸⣿⣮⡻⠿⣿⠿⣟⣫⣾⣿⣿⣿⣷⣶⣾⣿⡏⣿⣿⣿⡇ ⠄⠄⢸⣿⣿⣿⡇⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣇⣿⣿⣿⡇ ⠄⠄⢸⣿⣿⣿⡇⠄⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢸⣿⣿⣿⠄ ⠄⠄⣼⣿⣿⣿⢃⣾⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⡏⣿⣿⣿⡇⠄ ⠄⠄⠸⣿⣿⢣⢶⣟⣿⣖⣿⣷⣻⣮⡿⣽⣿⣻⣖⣶⣤⣭⡉⠄⠄⠄⠄⠄ ⠄⠄⠄⢹⠣⣛⣣⣭⣭⣭⣁⡛⠻⢽⣿⣿⣿⣿⢻⣿⣿⣿⣽⡧⡄⠄⠄⠄ ⠄⠄⠄⠄⣼⣿⣿⣿⣿⣿⣿⣿⣿⣶⣌⡛⢿⣽⢘⣿⣷⣿⡻⠏⣛⣀⠄⠄ ⠄⠄⠄⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣦⠙⡅⣿⠚⣡⣴⣿⣿⣿⡆⠄ ⠄⠄⣰⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⠄⣱⣾⣿⣿⣿⣿⣿⣿⠄ ⠄⢀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⢸⣿⣿⣿⣿⣿⣿⣿⣿⠄ ⠄⣸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠣⣿⣿⣿⣿⣿⣿⣿⣿⣿⠄ ⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠑⣿⣮⣝⣛⠿⠿⣿⣿⣿⣿⠄ ⢠⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⡟⠄ ⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠇⠄⠄⠄⠄⢹⣿⣿⣿⣿⣿⣿⣿⣿⠁⠄ ⣸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠄⠄⠄⠄⠄⠸⣿⣿⣿⣿⣿⡿⢟⣣⣀\n",
      "robinhood stock gets manipulated r wallstreetbets ⢀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⣠⣤⣶⣶ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⢰⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣧⣀⣀⣾⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⡏⠉⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿ ⣿⣿⣿⣿⣿⣿⠀⠀⠀⠈⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠉⠁⠀⣿ ⣿⣿⣿⣿⣿⣿⣧⡀⠀⠀⠀⠀⠙⠿⠿⠿⠻⠿⠿⠟⠿⠛⠉⠀⠀⠀⠀⠀⣸⣿ ⣿⣿⣿⣿⣿⣿⣿⣷⣄⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⣴⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡟⠀⠀⢰⣹⡆⠀⠀⠀⠀⠀⠀⣭⣷⠀⠀⠀⠸⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠈⠉⠀⠀⠤⠄⠀⠀⠀⠉⠁⠀⠀⠀⠀⢿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⢾⣿⣷⠀⠀⠀⠀⡠⠤⢄⠀⠀⠀⠠⣿⣿⣷⠀⢸⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡀⠉⠀⠀⠀⠀⠀⢄⠀⢀⠀⠀⠀⠀⠉⠉⠁⠀⠀⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿\n",
      "very nice breakdown op even i understood it if i had any gambling money left i would buy in the graph is remarkably similar to months clne https finance yahoo com quote clne chart p clne eyjpbnrlcnzhbciimrhesisinblcmlvzgljaxrijoxlcjawlvwpdcibnvsbcwiyfuzgxlvlkdggiojgsimzsaxbwzwqiomzhbhnllcjbxbwvvbmrlcmxhesidhjzswiywrqijpcnvllcjjcmzchhaxiionrydwusimnoyxjvhlwzsiimnhbmrszsisimvdgvuzgvkijpmywxzzswibwfyavuvzclvbnmiontlcjhzdyzwdhdglvblrcguioijvagxjiiwiyhhcnrtyfszsiimxpbmvhciisinndwrpzxmionsiocmdmsihvuzhligiwionsidhlwzsiinzvbcbbmryiiwiawwdxrzijpimlkijoiocmdmsihvuzhligiwilcjkaxnwbgfijoiocmdmsihvuzhligiwifswibvchvcyieyjvccbwbxbwuioiijmdbimdyxiiwirgbibwbxbwuioiijzmyzmznhinsinbhbmvsijoiyhhcnqilcjwyxjhbwvzxjzijpindpzhrormfjdgyijowljqlcjjagfydehbwuioijjagfydcjfxsinbhbmvscyieyjjagfydcieyjwzxjjzwijoxlcjkaxnwbgfijoiqxorsisimnoyxjtmftzsiimnoyxjiiwiawkzxgiojasinlbeglzijpimhbwuioijjagfydcisinbvclawuijpudwxsfswiewfaxnmsfmioltdlcjyxhpcjiuyiwyjjagfydcisiukajhzvbcbbmryocmilfswicvubhbiiesimxpbmvxawracimiwicryaxblzejhytncmbmqionrydwusimvzwcyidhjzswiysbiioiijmdamwyyiiwicryaxblzejhytncmzcidhjzswizxzlbnrnyxaionsiyycgyyxrlijpimrpdnmionrydwusinnwbglcyidhjzxsinnpzrldiielcjzewibxzijpbeyjzewibwioijdtefiiwicltymstjqzwnijpinnbwjvbciiknmtkuilcjxdwzvrcguioijfuvvjvfkilcjlegnoywnzvrpbwvablijoiqwlcmljysozxdfwwyayjlcjwzxjpbrpylesimswiawzxjywwioijkyxkilcjawlvwpdcibnvsbcwicvubhbiiexx except for the volume \n",
      "the horse will work again wkhs 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎 🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎🐎\n",
      "sofi is an absolute steal right now with a small short position of a little bit of buying pressure will put these shorts upside down on what is already a beautiful stock at bucks a share lfg 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀 🚀🚀🚀\n",
      "show him your cock that’s how u assert your dominance ⠹⣿⣿⣿⡿⠿⠛⠋⢉⣉⣉⠙⠻⠿⣿⣿⠿⠛⢉⣉⣉⠉⠛⠻⠿⣿⣿⣿⡿⠁ ⣆⠘⠿⠁⣠⣶⣾⠿⠷⣶⣭⣿⣶⣦⡀⢀⣴⣾⣿⣭⣶⠾⠿⣶⣦⡀⠹⠟⢀⣾ ⣿⣧⡀⢸⣯⣽⣿⡿⣻⡿⣫⣿⡏⣿⣷⣾⣿⢹⣿⣝⢿⣟⢿⣿⣯⣽⠀⣠⣿⣿ ⣿⣿⢷⣤⣈⠉⣉⠈⠛⠓⠿⣿⣷⣧⣿⣿⣼⣾⡿⠟⠚⠋⢁⡉⢉⣠⣴⡿⣿⣿ ⣿⡏⣾⣿⣿⡟⠛⠛⠻⠶⢤⠈⠉⡀⠀⠀⡈⠉⢠⠴⠾⠛⠛⠛⣿⣿⣿⣷⢹⣿ ⠻⣧⣿⣿⣿⠿⠿⠰⢰⣦⡄⠀⠂bull🍆 ⠀⠀⣤⣶⣶⠿⠿⢿⣿⣿⣿⡼⠋ ⡄⠈⠛⢿⣿⣶⣦⣤⣤⣈⡉⠀⠀⠀⠀⠀⠀⠀⠀⠈⣉⣠⣤⣤⣶⣾⣿⠟⠀⣴ ⡇⢸⣦⠀⢻⣄⠀⠉⠙⠻⠟⠀⣈⣀⣀⣀⣈⡀⠘⠿⠛⠉⠁⢀⣼⠃⢠⣾⠀⣿ ⡇⢸⣿⣧⡀⠻⠇⢸⣷⣶⣶⡾⢿⣿⢿⡿⣿⠿⣶⣶⣶⣿⠀⠿⠃⣠⣿⣿⠀⣿ ⡇⢸⢿⣫⣾⢖⣶⣾⡛⣿⣿⣧⠀⣯⢾⡷⡅⢠⣿⣿⣿⢛⣶⣶⡺⣷⣝⡿⠀⣿ ⡇⢸⠾⣹⢏⣺⣿⢫⣇⣻⣿⡏⢀⡴⢿⡿⢆⠈⣿⣿⣟⣸⡝⣿⣗⡹⣏⠷⠀⣿ ⡇⢸⡿⣣⣿⣿⣿⢻⣯⢻⣿⠃⡀⠐⠛⠛⠀⡀⢻⣿⡟⣽⡟⣿⣿⣿⣜⢿⠀⣿ ⡇⢸⡿⣻⣿⢿⣿⣼⣿⣇⡇⢰⣿⠀⣛⡃⢸⣷⠀⣿⣸⣿⣧⣿⡿⣿⣟⢿⠀⣿ ⡇⢨⡾⠿⢏⣾⣿⣿⢸⡿⠀⣾⣿⣦⣈⣠⣾⣿⡆⠸⣿⡇⣿⣿⣷⡹⠿⢷⠀⣿ ⡇⢸⣿⣿⢟⣽⣿⡇⣎⠇⢸⣿⣿⣿⣿⣿⣿⣿⣿⠀⢿⣱⢸⣿⣯⡻⣿⣿⠀⣿ u see that thats how u need your enemys waiting for bull pp fist on chest no fookin fear tesla will fooking rise to eow\n",
      "very nice breakdown op even i understood it if i had any gambling money left i would buy in the graph is remarkably similar to months clne https finance yahoo com quote clne chart p clne eyjpbnrlcnzhbciimrhesisinblcmlvzgljaxrijoxlcjawlvwpdcibnvsbcwiyfuzgxlvlkdggiojgsimzsaxbwzwqiomzhbhnllcjbxbwvvbmrlcmxhesidhjzswiywrqijpcnvllcjjcmzchhaxiionrydwusimnoyxjvhlwzsiimnhbmrszsisimvdgvuzgvkijpmywxzzswibwfyavuvzclvbnmiontlcjhzdyzwdhdglvblrcguioijvagxjiiwiyhhcnrtyfszsiimxpbmvhciisinndwrpzxmionsiocmdmsihvuzhligiwionsidhlwzsiinzvbcbbmryiiwiawwdxrzijpimlkijoiocmdmsihvuzhligiwilcjkaxnwbgfijoiocmdmsihvuzhligiwifswibvchvcyieyjvccbwbxbwuioiijmdbimdyxiiwirgbibwbxbwuioiijzmyzmznhinsinbhbmvsijoiyhhcnqilcjwyxjhbwvzxjzijpindpzhrormfjdgyijowljqlcjjagfydehbwuioijjagfydcjfxsinbhbmvscyieyjjagfydcieyjwzxjjzwijoxlcjkaxnwbgfijoiqxorsisimnoyxjtmftzsiimnoyxjiiwiawkzxgiojasinlbeglzijpimhbwuioijjagfydcisinbvclawuijpudwxsfswiewfaxnmsfmioltdlcjyxhpcjiuyiwyjjagfydcisiukajhzvbcbbmryocmilfswicvubhbiiesimxpbmvxawracimiwicryaxblzejhytncmbmqionrydwusimvzwcyidhjzswiysbiioiijmdamwyyiiwicryaxblzejhytncmzcidhjzswizxzlbnrnyxaionsiyycgyyxrlijpimrpdnmionrydwusinnwbglcyidhjzxsinnpzrldiielcjzewibxzijpbeyjzewibwioijdtefiiwicltymstjqzwnijpinnbwjvbciiknmtkuilcjxdwzvrcguioijfuvvjvfkilcjlegnoywnzvrpbwvablijoiqwlcmljysozxdfwwyayjlcjwzxjpbrpylesimswiawzxjywwioijkyxkilcjawlvwpdcibnvsbcwicvubhbiiexx except for the volume \n",
      "if you bought baba calls ⣿⣿⣿⣿⣿⠟⠋⠄⠄⠄⠄⠄⠄⠄⢁⠈⢻⢿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⠃⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠈⡀⠭⢿⣿⣿⣿⣿ ⣿⣿⣿⣿⡟⠄⢀⣾⣿⣿⣿⣷⣶⣿⣷⣶⣶⡆⠄⠄⠄⣿⣿⣿⣿ ⣿⣿⣿⣿⡇⢀⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣧⠄⠄⢸⣿⣿⣿⣿ ⣿⣿⣿⣿⣇⣼⣿⣿⠿⠶⠙⣿⡟⠡⣴⣿⣽⣿⣧⠄⢸⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣾⣿⣿⣟⣭⣾⣿⣷⣶⣶⣴⣶⣿⣿⢄⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⡟⣩⣿⣿⣿⡏⢻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣹⡋⠘⠷⣦⣀⣠⡶⠁⠈⠁⠄⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣍⠃⣴⣶⡔⠒⠄⣠⢀⠄⠄⠄⡨⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣦⡘⠿⣷⣿⠿⠟⠃⠄⠄⣠⡇⠈⠻⣿⣿⣿⣿ ⣿⣿⣿⣿⡿⠟⠋⢁⣷⣠⠄⠄⠄⠄⣀⣠⣾⡟⠄⠄⠄⠄⠉⠙⠻ ⡿⠟⠋⠁⠄⠄⠄⢸⣿⣿⡯⢓⣴⣾⣿⣿⡟⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⣿⡟⣷⠄⠹⣿⣿⣿⡿⠁⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⣸⣿⡷⡇⠄⣴⣾⣿⣿⠃⠄⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⣿⣿⠃⣦⣄⣿⣿⣿⠇⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⢸⣿⠗⢈⡶⣷⣿⣿⡏⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄ china thanks you for your sacrifice comrade \n"
     ]
    }
   ],
   "source": [
    "# loop through all comments to generate scores\n",
    "\n",
    "scores = []\n",
    "\n",
    "for comment in reddit_df_filtered.body.values:\n",
    "    \n",
    "    try:\n",
    "        sentiment_probs = list(b_sentiment.classify(comment))\n",
    "        prediction = sentiment_probs.index(max(sentiment_probs))\n",
    "        scores.append(prediction)\n",
    "    \n",
    "    except:\n",
    "        # if edgecase occurs output neutral sentiment \n",
    "        print(comment)\n",
    "        scores.append(1)\n",
    "\n",
    "reddit_df_filtered['bert_sentiment'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    158320\n",
       "0     92897\n",
       "2     49154\n",
       "Name: bert_sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df_filtered['bert_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Stock</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>weighted_sentiment</th>\n",
       "      <th>bert_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>okay which one of you autists loaded up on wis...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ahh the old ecvt wish clne clov and bb baghold...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>wish finally dead</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>wish dip bought</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629147e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>unsure i wish i knew</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629146e+09</td>\n",
       "      <td>2021-08-16 20</td>\n",
       "      <td>08</td>\n",
       "      <td>16</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  score   created_utc  \\\n",
       "30   okay which one of you autists loaded up on wis...    1.0  1.629147e+09   \n",
       "59   ahh the old ecvt wish clne clov and bb baghold...    1.0  1.629147e+09   \n",
       "74                                  wish finally dead     1.0  1.629147e+09   \n",
       "78                                     wish dip bought    1.0  1.629147e+09   \n",
       "238                               unsure i wish i knew    1.0  1.629146e+09   \n",
       "\n",
       "              date month day Stock  vader_sentiment  weighted_sentiment  \\\n",
       "30   2021-08-16 20    08  16  wish           0.5574              0.5574   \n",
       "59   2021-08-16 20    08  16  wish           0.3612              0.3612   \n",
       "74   2021-08-16 20    08  16  wish          -0.3818             -0.3818   \n",
       "78   2021-08-16 20    08  16  wish           0.4019              0.4019   \n",
       "238  2021-08-16 20    08  16  wish           0.1779              0.1779   \n",
       "\n",
       "     bert_sentiment  \n",
       "30                1  \n",
       "59                1  \n",
       "74                0  \n",
       "78                1  \n",
       "238               1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the RoBERTa model on the full dataset takes a few hours so the final data set is saved as a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df_filtered = pd.read_csv('reddit_sentiment_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting next day direction with sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, KFold\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import datetime \n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing stock data from yfinance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import datetime \n",
    "import pytz\n",
    "\n",
    "stock_list = ['gme', 'amc', 'wish', 'spy', 'clov','bb']\n",
    "\n",
    "def get_closing_values(stocks = stock_list, start='2021-06-18', end='2021-08-16', interval='1h'):\n",
    "    \n",
    "    # Create empty dataframe to populate stock close into \n",
    "    price_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through stock list to collect closing prices \n",
    "    for stock in stocks:\n",
    "        stock_connection = yf.Ticker(stock.upper())\n",
    "        hist = stock_connection.history(start='2021-06-18', end='2021-08-16', interval='1h')\n",
    "        close_price = hist['Close']\n",
    "        price_df[stock] = close_price\n",
    "    \n",
    "    \n",
    "    # Create timezone to UTC\n",
    "    def change_timezone(time):\n",
    "        local = pytz.timezone(\"America/New_York\")\n",
    "        naive = datetime.datetime.strptime(time, \"%Y-%m-%d %H\")\n",
    "        local_dt = local.localize(naive, is_dst=None)\n",
    "        utc_dt = local_dt.astimezone(pytz.utc)\n",
    "        \n",
    "        return utc_dt\n",
    "    \n",
    "    # Adjusting dates to UTC\n",
    "    price_df['date'] = hist.index\n",
    "    price_df['date'] = price_df.apply(lambda row: row['date'].strftime('%Y-%m-%d %H'), axis=1)\n",
    "    price_df['date'] = price_df.apply(lambda row: change_timezone(row.date).strftime('%Y-%m-%d %H'), axis=1)\n",
    "    price_df = price_df.reset_index(drop=True)\n",
    "    \n",
    "    # Melt dataframe \n",
    "    price_df = pd.melt(price_df, id_vars='date', var_name='Stock', value_name='close')\n",
    "    \n",
    "    return price_df\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1680, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df = get_closing_values()\n",
    "price_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hourly price/sentiment data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>date</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>weighted_sentiment</th>\n",
       "      <th>count</th>\n",
       "      <th>bert_sentiment</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 13</td>\n",
       "      <td>0.080077</td>\n",
       "      <td>0.826847</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>62.240002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 14</td>\n",
       "      <td>0.083206</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>62.412701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 15</td>\n",
       "      <td>0.113618</td>\n",
       "      <td>0.305963</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>61.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 16</td>\n",
       "      <td>0.046904</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>61.328300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 17</td>\n",
       "      <td>0.124686</td>\n",
       "      <td>0.900386</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>60.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 18</td>\n",
       "      <td>0.067952</td>\n",
       "      <td>1.220267</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>58.109901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-18 19</td>\n",
       "      <td>0.030102</td>\n",
       "      <td>0.049684</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>59.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-21 13</td>\n",
       "      <td>0.081404</td>\n",
       "      <td>2.616489</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>58.849998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-21 14</td>\n",
       "      <td>0.073789</td>\n",
       "      <td>0.017903</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>56.419498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amc</td>\n",
       "      <td>2021-06-21 15</td>\n",
       "      <td>0.068178</td>\n",
       "      <td>0.028838</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>55.549999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock           date  vader_sentiment  weighted_sentiment  count  \\\n",
       "0   amc  2021-06-18 13         0.080077            0.826847    142   \n",
       "1   amc  2021-06-18 14         0.083206            0.936330    108   \n",
       "2   amc  2021-06-18 15         0.113618            0.305963     89   \n",
       "3   amc  2021-06-18 16         0.046904            0.030554     93   \n",
       "4   amc  2021-06-18 17         0.124686            0.900386     70   \n",
       "5   amc  2021-06-18 18         0.067952            1.220267     96   \n",
       "6   amc  2021-06-18 19         0.030102            0.049684    140   \n",
       "7   amc  2021-06-21 13         0.081404            2.616489     73   \n",
       "8   amc  2021-06-21 14         0.073789            0.017903     76   \n",
       "9   amc  2021-06-21 15         0.068178            0.028838     82   \n",
       "\n",
       "   bert_sentiment      close  \n",
       "0               1  62.240002  \n",
       "1               1  62.412701  \n",
       "2               1  61.540001  \n",
       "3               1  61.328300  \n",
       "4               1  60.680000  \n",
       "5               1  58.109901  \n",
       "6               1  59.380001  \n",
       "7               1  58.849998  \n",
       "8               1  56.419498  \n",
       "9               1  55.549999  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "# group sentiment by family \n",
    "hourly_sentiment = reddit_df_filtered.groupby(by=['Stock','date']).agg({'vader_sentiment':'mean', 'weighted_sentiment':'mean', 'Stock':'count','bert_sentiment':lambda x: mode(x)[0][0]}).rename(columns={'Stock':'count'}).reset_index()\n",
    "\n",
    "# Merge hourly stock price data with hourly sentiment data for each stock\n",
    "price_sentiment = pd.merge(hourly_sentiment, price_df, how='inner', on=['Stock','date'])\n",
    "\n",
    "price_sentiment.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Feature enginnering prior to Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbal_score(x):\n",
    "    \n",
    "    if x >=0.01:\n",
    "        return 'positive'\n",
    "    \n",
    "    elif x < 0.01 and x > -0.01: \n",
    "        return 'neutral'\n",
    "    \n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "def bert_score(x):\n",
    "    \n",
    "    if x == 2:\n",
    "        return 'positive'\n",
    "    \n",
    "    elif x == 1:\n",
    "        return 'neutral'\n",
    "    \n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Change scores into positive, negative, and neutral \n",
    "price_sentiment['vader_score'] = price_sentiment['vader_sentiment'].apply(lambda c: verbal_score(c))\n",
    "price_sentiment['weighted_score'] = price_sentiment['weighted_sentiment'].apply(lambda c: verbal_score(c))\n",
    "price_sentiment['bert_score'] = price_sentiment['bert_sentiment'].apply(lambda c: bert_score(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1274\n",
       "negative     302\n",
       "neutral      104\n",
       "Name: vader_score, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sentiment['vader_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1187\n",
       "negative     462\n",
       "neutral       31\n",
       "Name: weighted_score, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sentiment['weighted_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     1380\n",
       "negative     283\n",
       "positive      17\n",
       "Name: bert_score, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sentiment['bert_score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through all stocks and generating roc-auc results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_results_df = pd.DataFrame()\n",
    "\n",
    "for stock in stock_list:\n",
    "    stock_df = price_sentiment.copy()\n",
    "    stock_df = stock_df[stock_df['Stock'] == stock]\n",
    "    \n",
    "    # apply log-change \n",
    "    stock_df['log_change'] = np.log(stock_df.close) - np.log(stock_df.close.shift(1))\n",
    "    \n",
    "    # Create binary label for prediction \n",
    "    stock_df = stock_df.dropna()\n",
    "    stock_df['direction'] = stock_df['log_change'].apply(lambda x: 1 if x >0 else 0)\n",
    "    label_imbalance = stock_df.direction.value_counts()[0]/stock_df.direction.count()\n",
    "    \n",
    "    # Create t-1 price change variable \n",
    "    stock_df['t-1'] = stock_df.log_change.shift(1)\n",
    "    \n",
    "    for focus in ['weighted_score','vader_score','count','normal', 'bert_score']:\n",
    "        \n",
    "        if focus in ['weighted_score','vader_score','bert_score']:\n",
    "    \n",
    "            dummies = pd.get_dummies(stock_df[focus])\n",
    "            stock_df = pd.concat([stock_df, dummies], axis=1)\n",
    "            stock_df = stock_df.dropna()\n",
    "            \n",
    "            try:\n",
    "                X = stock_df[['negative','neutral','positive','t-1']]\n",
    "                y = stock_df['direction']\n",
    "            \n",
    "            except:\n",
    "                X = stock_df[['negative','positive','t-1']]\n",
    "                y = stock_df['direction']\n",
    "        \n",
    "        elif focus == 'normal':\n",
    "            X = stock_df[['t-1']]\n",
    "            y = stock_df['direction']\n",
    "        \n",
    "        else:\n",
    "            X = stock_df[['count','t-1']]\n",
    "            y = stock_df['direction']\n",
    "            \n",
    "                \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, shuffle=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_hat = clf.predict(X_test) \n",
    "        accuracy = (y_hat==y_test).mean() \n",
    "        \n",
    "        k_fold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        output = cross_validate(clf, X, y, cv=k_fold, scoring = 'roc_auc', return_estimator =False)['test_score'].mean()\n",
    "        model_results_df = model_results_df.append({'Stock': stock, 'Variable':focus, 'Positive Imbalance': np.round(label_imbalance, 2), 'ROC_AUC': np.round(output, 2), 'Accuracy':np.round(accuracy, 2)}, ignore_index=True)\n",
    "\n",
    "model_results_df = model_results_df[['Stock','Positive Imbalance', 'Variable', 'ROC_AUC', 'Accuracy']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Positive Imbalance</th>\n",
       "      <th>Variable</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gme</td>\n",
       "      <td>0.55</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gme</td>\n",
       "      <td>0.55</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gme</td>\n",
       "      <td>0.55</td>\n",
       "      <td>count</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gme</td>\n",
       "      <td>0.55</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gme</td>\n",
       "      <td>0.55</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amc</td>\n",
       "      <td>0.55</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amc</td>\n",
       "      <td>0.55</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amc</td>\n",
       "      <td>0.55</td>\n",
       "      <td>count</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amc</td>\n",
       "      <td>0.55</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amc</td>\n",
       "      <td>0.55</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.55</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.55</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.55</td>\n",
       "      <td>count</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.55</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.55</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spy</td>\n",
       "      <td>0.40</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spy</td>\n",
       "      <td>0.40</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spy</td>\n",
       "      <td>0.40</td>\n",
       "      <td>count</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spy</td>\n",
       "      <td>0.40</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spy</td>\n",
       "      <td>0.40</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clov</td>\n",
       "      <td>0.57</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>clov</td>\n",
       "      <td>0.57</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>clov</td>\n",
       "      <td>0.57</td>\n",
       "      <td>count</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clov</td>\n",
       "      <td>0.57</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>clov</td>\n",
       "      <td>0.57</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.52</td>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.52</td>\n",
       "      <td>vader_score</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.52</td>\n",
       "      <td>count</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.52</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bb</td>\n",
       "      <td>0.52</td>\n",
       "      <td>bert_score</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stock  Positive Imbalance        Variable  ROC_AUC  Accuracy\n",
       "0    gme                0.55  weighted_score     0.46      0.56\n",
       "1    gme                0.55     vader_score     0.43      0.50\n",
       "2    gme                0.55           count     0.51      0.51\n",
       "3    gme                0.55          normal     0.53      0.54\n",
       "4    gme                0.55      bert_score     0.44      0.53\n",
       "5    amc                0.55  weighted_score     0.55      0.54\n",
       "6    amc                0.55     vader_score     0.52      0.49\n",
       "7    amc                0.55           count     0.48      0.54\n",
       "8    amc                0.55          normal     0.54      0.54\n",
       "9    amc                0.55      bert_score     0.47      0.49\n",
       "10  wish                0.55  weighted_score     0.52      0.51\n",
       "11  wish                0.55     vader_score     0.52      0.51\n",
       "12  wish                0.55           count     0.49      0.53\n",
       "13  wish                0.55          normal     0.56      0.53\n",
       "14  wish                0.55      bert_score     0.55      0.51\n",
       "15   spy                0.40  weighted_score     0.49      0.56\n",
       "16   spy                0.40     vader_score     0.46      0.57\n",
       "17   spy                0.40           count     0.44      0.57\n",
       "18   spy                0.40          normal     0.49      0.57\n",
       "19   spy                0.40      bert_score     0.44      0.59\n",
       "20  clov                0.57  weighted_score     0.53      0.57\n",
       "21  clov                0.57     vader_score     0.55      0.54\n",
       "22  clov                0.57           count     0.43      0.56\n",
       "23  clov                0.57          normal     0.51      0.56\n",
       "24  clov                0.57      bert_score     0.53      0.57\n",
       "25    bb                0.52  weighted_score     0.55      0.49\n",
       "26    bb                0.52     vader_score     0.53      0.49\n",
       "27    bb                0.52           count     0.47      0.57\n",
       "28    bb                0.52          normal     0.55      0.51\n",
       "29    bb                0.52      bert_score     0.53      0.43"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_df.to_csv('model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
